1.graphite
http://blog.csdn.net/wangli61289/article/details/45077795
http://graphite.wikidot.com/installation 

http://graphite.wikidot.com/downloads
https://pypi.python.org/packages/88/97/090c6e0cadf14487e9902b44565c761332f235c93ebf036b2dcf65291234/whisper-0.9.12.tar.gz 
https://pypi.python.org/packages/ea/23/960426078eff1c0b99b15728d41f9069108d897057a77548f34db7bdb2af/carbon-0.9.12.tar.gz 
https://pypi.python.org/packages/af/52/df7b13c12a66e7d0cef87fa683825f72c14e593c79e570120fd266019d45/graphite-web-0.9.12.tar.gz 


2. grafana integrate graphite
https://segmentfault.com/a/1190000000693520 

http://grafanarel.s3.amazonaws.com/grafana-1.8.0.zip 
zip -r t.zip dir/*
unzip -d /home/kevin/xxx/  *.zip

http://mirrors.sohu.com/nginx/
http://mirrors.sohu.com/nginx/nginx-1.2.8.tar.gz

3.grafana configure
http://docs.grafana.org/installation/debian/


4.hadoop2.6.4  
http://mirrors.cnnic.cn/apache/hadoop/common/hadoop-2.6.4/hadoop-2.6.4-src.tar.gz 
http://apache.fayea.com/hadoop/common/hadoop-2.6.4/hadoop-2.6.4.tar.gz 
Î±·Ö²¼Ê½¼¯Èº£º
http://www.powerxing.com/install-hadoop/
http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/ClusterSetup.html#Installation

5.spark1.6.2
Spark runs on Java 7+, Python 2.6+ and R 3.1+. For the Scala API, Spark 1.6.2 uses Scala 2.10. You will need to use a compatible Scala version (2.10.x).
dpkg -i  x.deb
http://downloads.lightbend.com/scala/2.10.6/scala-2.10.6.deb 
http://downloads.lightbend.com/scala/2.10.6/scala-2.10.6.tgz 

http://apache.fayea.com/spark/spark-1.6.2/spark-1.6.2-bin-hadoop2.6.tgz



